{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwXgriySBdzr",
        "outputId": "bc02d6fc-d41c-4f8b-ed67-ca5ecc393bba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.9.24)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_tAiOCDBlCW"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZqnLMOjBsxA",
        "outputId": "39962a95-f3f6-48f9-fc43-d4ceeb64351c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading face-expression-recognition-dataset.zip to /content\n",
            " 87% 105M/121M [00:02<00:00, 48.3MB/s] \n",
            "100% 121M/121M [00:02<00:00, 52.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d jonathanoheix/face-expression-recognition-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p12or71B9cV"
      },
      "outputs": [],
      "source": [
        "!unzip /content/face-expression-recognition-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1j60aLBB9FC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDttevD0CUcN"
      },
      "outputs": [],
      "source": [
        "train_dir='/content/images/train'\n",
        "val_dir='/content/images/validation'\n",
        "img_height=160\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t01unMLCnX3"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "core_idg = ImageDataGenerator(rescale=(1/255.),\n",
        "                              horizontal_flip = True, \n",
        "                              vertical_flip = False, \n",
        "                              height_shift_range= 0.05, \n",
        "                              width_shift_range=0.1, \n",
        "                              rotation_range=5, \n",
        "                              shear_range = 0.1,\n",
        "                              fill_mode = 'reflect'\n",
        "                            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHtex_CmCu53",
        "outputId": "5d8cf033-e312-4af0-dabf-fc2f0e7b1ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 28821 images belonging to 7 classes.\n",
            "Found 7066 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = core_idg.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(160,160),\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical',\n",
        "    batch_size=128,\n",
        "    seed=11,\n",
        "    )\n",
        "valid_ds = core_idg.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(160,160),\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical',\n",
        "    batch_size=128,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFmBXgJvD7tz"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(160,160,1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFazLCN9Ea8S"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate\t= 0.01), \n",
        "                         loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-rD10c-E-sR",
        "outputId": "63b10e68-7a16-4bbd-a2ba-93167c8abee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "226/226 [==============================] - 107s 470ms/step - loss: 1.1766 - accuracy: 0.5545 - val_loss: 1.5640 - val_accuracy: 0.5650\n",
            "Epoch 2/10\n",
            "226/226 [==============================] - 104s 458ms/step - loss: 1.1433 - accuracy: 0.5688 - val_loss: 1.1413 - val_accuracy: 0.5655\n",
            "Epoch 3/10\n",
            "226/226 [==============================] - 106s 468ms/step - loss: 1.1314 - accuracy: 0.5741 - val_loss: 1.1527 - val_accuracy: 0.5698\n",
            "Epoch 4/10\n",
            "226/226 [==============================] - 102s 452ms/step - loss: 1.2179 - accuracy: 0.5360 - val_loss: 4.7305 - val_accuracy: 0.2086\n",
            "Epoch 5/10\n",
            "226/226 [==============================] - 102s 450ms/step - loss: 1.6234 - accuracy: 0.3531 - val_loss: 1.5356 - val_accuracy: 0.3963\n",
            "Epoch 6/10\n",
            "226/226 [==============================] - 102s 451ms/step - loss: 1.4827 - accuracy: 0.4239 - val_loss: 1.6176 - val_accuracy: 0.4120\n",
            "Epoch 7/10\n",
            "226/226 [==============================] - 102s 451ms/step - loss: 1.3990 - accuracy: 0.4604 - val_loss: 1.4318 - val_accuracy: 0.4609\n",
            "Epoch 8/10\n",
            "226/226 [==============================] - 102s 450ms/step - loss: 1.3453 - accuracy: 0.4839 - val_loss: 1.5011 - val_accuracy: 0.4557\n",
            "Epoch 9/10\n",
            "226/226 [==============================] - 102s 452ms/step - loss: 1.2954 - accuracy: 0.5053 - val_loss: 1.3578 - val_accuracy: 0.5028\n",
            "Epoch 10/10\n",
            "226/226 [==============================] - 102s 450ms/step - loss: 1.2547 - accuracy: 0.5250 - val_loss: 1.4481 - val_accuracy: 0.4764\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds,\n",
        "                    verbose=1, epochs=10,validation_data=valid_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP3z0I8YMQp_"
      },
      "outputs": [],
      "source": [
        "def create_model(base_model):\n",
        "    base_model.trainable = False\n",
        "    global_average_layer = tf.keras.layers.GlobalMaxPooling2D()(base_model.output)\n",
        "    x4 = tf.keras.layers.Dense(512, activation='relu')(global_average_layer)\n",
        "    x5 = tf.keras.layers.BatchNormalization()(x4)\n",
        "    x6 = tf.keras.layers.Dropout(0.5)(x5)\n",
        "    prediction_layer = tf.keras.layers.Dense(7, activation='softmax')(x6)\n",
        "    model = tf.keras.models.Model(inputs=base_model.input, outputs=prediction_layer)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZes5PfHMX19"
      },
      "outputs": [],
      "source": [
        "base_model4 = tf.keras.applications.Xception(input_shape=(224, 224,3),include_top=False, weights=\"imagenet\")\n",
        "model = create_model(base_model4)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                 loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                 metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B8ie-dlMnCR",
        "outputId": "bb6aa4e3-938b-42c2-bf79-9f0d48b6c39a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "226/226 [==============================] - 400s 2s/step - loss: 1.7901 - accuracy: 0.3818 - val_loss: 1.4886 - val_accuracy: 0.4369\n",
            "Epoch 2/10\n",
            "226/226 [==============================] - 393s 2s/step - loss: 1.4946 - accuracy: 0.4385 - val_loss: 1.4211 - val_accuracy: 0.4629\n",
            "Epoch 3/10\n",
            "226/226 [==============================] - 393s 2s/step - loss: 1.4383 - accuracy: 0.4536 - val_loss: 1.4864 - val_accuracy: 0.4403\n",
            "Epoch 4/10\n",
            "226/226 [==============================] - 392s 2s/step - loss: 1.4147 - accuracy: 0.4660 - val_loss: 1.3844 - val_accuracy: 0.4707\n",
            "Epoch 5/10\n",
            "226/226 [==============================] - 393s 2s/step - loss: 1.3974 - accuracy: 0.4680 - val_loss: 1.3791 - val_accuracy: 0.4745\n",
            "Epoch 6/10\n",
            "226/226 [==============================] - 391s 2s/step - loss: 1.3921 - accuracy: 0.4727 - val_loss: 1.6121 - val_accuracy: 0.4172\n",
            "Epoch 7/10\n",
            "226/226 [==============================] - 391s 2s/step - loss: 1.3866 - accuracy: 0.4735 - val_loss: 1.3920 - val_accuracy: 0.4714\n",
            "Epoch 8/10\n",
            "226/226 [==============================] - 392s 2s/step - loss: 1.3814 - accuracy: 0.4720 - val_loss: 1.3695 - val_accuracy: 0.4837\n",
            "Epoch 9/10\n",
            "226/226 [==============================] - 394s 2s/step - loss: 1.3770 - accuracy: 0.4765 - val_loss: 1.3915 - val_accuracy: 0.4737\n",
            "Epoch 10/10\n",
            "226/226 [==============================] - 393s 2s/step - loss: 1.3727 - accuracy: 0.4828 - val_loss: 1.3654 - val_accuracy: 0.4812\n"
          ]
        }
      ],
      "source": [
        "hist_x = model.fit(train_ds, epochs=10,\n",
        "                    validation_data = valid_ds, \n",
        "                    verbose = 1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}