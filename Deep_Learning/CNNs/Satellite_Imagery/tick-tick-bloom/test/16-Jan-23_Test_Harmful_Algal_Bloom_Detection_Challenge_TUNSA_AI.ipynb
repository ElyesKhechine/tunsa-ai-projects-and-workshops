{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d63c79c-1cd6-4fc2-aec8-2bbaac0c5a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install pystac\\n!pip install pystac_client\\n!pip install planetary_computer\\n!pip install nb_black\\n!pip install odc-stac\\n!pip install geopandas\\n!pip install rioxarray\\n!pip install loguru\\n!pip install opencv-python\\n!pip install geopy\\n!pip install path\\n!pip install tqdm'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip install pystac\n",
    "!pip install pystac_client\n",
    "!pip install planetary_computer\n",
    "!pip install nb_black\n",
    "!pip install odc-stac\n",
    "!pip install geopandas\n",
    "!pip install rioxarray\n",
    "!pip install loguru\n",
    "!pip install opencv-python\n",
    "!pip install geopy\n",
    "!pip install path\n",
    "!pip install tqdm\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea401cb-60be-49b7-8789-42e04efcd30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "124fda36-8616-4f44-b3c6-c78823cf5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import odc.stac\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a8f3ec8-c566-4f25-8672-c8448c9a355d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = (\n",
    "    Path.cwd().parent.resolve()\n",
    "    / r\"C:\\Projects\\Tick_Tick_Bloom_Harmful_Algal_Bloom_Detection_Challenge\\data\"\n",
    ")\n",
    "assert DATA_DIR.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838b565-1429-4aed-8c17-9aaa3f24e82c",
   "metadata": {},
   "source": [
    "# **metadata.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e64cc3-7be6-4848-9261-855c794f1d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabm</td>\n",
       "      <td>39.080319</td>\n",
       "      <td>-86.430867</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aabn</td>\n",
       "      <td>36.559700</td>\n",
       "      <td>-121.510000</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aacd</td>\n",
       "      <td>35.875083</td>\n",
       "      <td>-78.878434</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaee</td>\n",
       "      <td>35.487000</td>\n",
       "      <td>-79.062133</td>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaff</td>\n",
       "      <td>38.049471</td>\n",
       "      <td>-99.827001</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid   latitude   longitude        date  split\n",
       "0  aabm  39.080319  -86.430867  2018-05-14  train\n",
       "1  aabn  36.559700 -121.510000  2016-08-31   test\n",
       "2  aacd  35.875083  -78.878434  2020-11-19  train\n",
       "3  aaee  35.487000  -79.062133  2016-08-24  train\n",
       "4  aaff  38.049471  -99.827001  2019-07-23  train"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(DATA_DIR / \"metadata.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b802fd67-c1e7-44fe-9945-986c0013d60a",
   "metadata": {},
   "source": [
    "# **train_labels.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "869b18e8-e649-40b7-88a6-c0062ec2f437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabm</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1</td>\n",
       "      <td>585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aacd</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaee</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "      <td>1614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaff</td>\n",
       "      <td>midwest</td>\n",
       "      <td>3</td>\n",
       "      <td>111825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aafl</td>\n",
       "      <td>midwest</td>\n",
       "      <td>4</td>\n",
       "      <td>2017313.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid   region  severity    density\n",
       "0  aabm  midwest         1      585.0\n",
       "1  aacd    south         1      290.0\n",
       "2  aaee    south         1     1614.0\n",
       "3  aaff  midwest         3   111825.0\n",
       "4  aafl  midwest         4  2017313.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv(DATA_DIR / \"train_labels.csv\")\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94f16b-1c65-463d-be09-f318f5c9d948",
   "metadata": {},
   "source": [
    "# **Process feature data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37ff3f94-be2e-4265-8c0d-82ae76adfa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "from IPython.display import Image\n",
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9277bd08-8cdf-4a33-b60e-2858f44b2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the STAC API\n",
    "import planetary_computer as pc\n",
    "from pystac_client import Client\n",
    "\n",
    "catalog = Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\", modifier=pc.sign_inplace\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "092ce122-a403-4a9b-9115-6d88eeee455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance as distance\n",
    "\n",
    "# get our bounding box to search latitude and longitude coordinates\n",
    "def get_bounding_box(latitude, longitude, meter_buffer=50000):\n",
    "    \"\"\"\n",
    "    Given a latitude, longitude, and buffer in meters, returns a bounding\n",
    "    box around the point with the buffer on the left, right, top, and bottom.\n",
    "\n",
    "    Returns a list of [minx, miny, maxx, maxy]\n",
    "    \"\"\"\n",
    "    distance_search = distance.distance(meters=meter_buffer)\n",
    "\n",
    "    # calculate the lat/long bounds based on ground distance\n",
    "    # bearings are cardinal directions to move (south, west, north, and east)\n",
    "    min_lat = distance_search.destination((latitude, longitude), bearing=180)[0]\n",
    "    min_long = distance_search.destination((latitude, longitude), bearing=270)[1]\n",
    "    max_lat = distance_search.destination((latitude, longitude), bearing=0)[0]\n",
    "    max_long = distance_search.destination((latitude, longitude), bearing=90)[1]\n",
    "\n",
    "    return [min_long, min_lat, max_long, max_lat]\n",
    "\n",
    "\n",
    "# get our date range to search, and format correctly for query\n",
    "def get_date_range(date, time_buffer_days=15):\n",
    "    \"\"\"Get a date range to search for in the planetary computer based\n",
    "    on a sample's date. The time range will include the sample date\n",
    "    and time_buffer_days days prior\n",
    "\n",
    "    Returns a string\"\"\"\n",
    "    datetime_format = \"%Y-%m-%dT\"\n",
    "    range_start = pd.to_datetime(date) - timedelta(days=time_buffer_days)\n",
    "    date_range = f\"{range_start.strftime(datetime_format)}/{pd.to_datetime(date).strftime(datetime_format)}\"\n",
    "\n",
    "    return date_range\n",
    "\n",
    "\n",
    "def crop_sentinel_image(item, bounding_box):\n",
    "    \"\"\"\n",
    "    Given a STAC item from Sentinel-2 and a bounding box tuple in the format\n",
    "    (minx, miny, maxx, maxy), return a cropped portion of the item's visual\n",
    "    imagery in the bounding box.\n",
    "\n",
    "    Returns the image as a numpy array with dimensions (color band, height, width)\n",
    "    \"\"\"\n",
    "    (minx, miny, maxx, maxy) = bounding_box\n",
    "\n",
    "    image = rioxarray.open_rasterio(pc.sign(item.assets[\"visual\"].href)).rio.clip_box(\n",
    "        minx=minx,\n",
    "        miny=miny,\n",
    "        maxx=maxx,\n",
    "        maxy=maxy,\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "\n",
    "    return image.to_numpy()\n",
    "\n",
    "\n",
    "def crop_landsat_image(item, bounding_box):\n",
    "    \"\"\"\n",
    "    Given a STAC item from Landsat and a bounding box tuple in the format\n",
    "    (minx, miny, maxx, maxy), return a cropped portion of the item's visual\n",
    "    imagery in the bounding box.\n",
    "\n",
    "    Returns the image as a numpy array with dimensions (color band, height, width)\n",
    "    \"\"\"\n",
    "    (minx, miny, maxx, maxy) = bounding_box\n",
    "\n",
    "    image = odc.stac.stac_load(\n",
    "        [pc.sign(item)], bands=[\"red\", \"green\", \"blue\"], bbox=[minx, miny, maxx, maxy]\n",
    "    ).isel(time=0)\n",
    "    image_array = image[[\"red\", \"green\", \"blue\"]].to_array().to_numpy()\n",
    "\n",
    "    # normalize to 0 - 255 values\n",
    "    image_array = cv2.normalize(image_array, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "\n",
    "# Refactor our process from above into functions\n",
    "def select_best_item(items, date, latitude, longitude):\n",
    "    \"\"\"\n",
    "    Select the best satellite item given a sample's date, latitude, and longitude.\n",
    "    If any Sentinel-2 imagery is available, returns the closest sentinel-2 image by\n",
    "    time. Otherwise, returns the closest Landsat imagery.\n",
    "\n",
    "    Returns a tuple of (STAC item, item platform name, item date)\n",
    "    \"\"\"\n",
    "    # get item details\n",
    "    item_details = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"datetime\": item.datetime.strftime(\"%Y-%m-%d\"),\n",
    "                \"platform\": item.properties[\"platform\"],\n",
    "                \"min_long\": item.bbox[0],\n",
    "                \"max_long\": item.bbox[2],\n",
    "                \"min_lat\": item.bbox[1],\n",
    "                \"max_lat\": item.bbox[3],\n",
    "                \"item_obj\": item,\n",
    "            }\n",
    "            for item in items\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # filter to items that contain the point location, or return None if none contain the point\n",
    "    item_details[\"contains_sample_point\"] = (\n",
    "        (item_details.min_lat < latitude)\n",
    "        & (item_details.max_lat > latitude)\n",
    "        & (item_details.min_long < longitude)\n",
    "        & (item_details.max_long > longitude)\n",
    "    )\n",
    "    item_details = item_details[item_details[\"contains_sample_point\"] == True]\n",
    "    if len(item_details) == 0:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "\n",
    "    # add time difference between each item and the sample\n",
    "    item_details[\"time_diff\"] = pd.to_datetime(date) - pd.to_datetime(\n",
    "        item_details[\"datetime\"]\n",
    "    )\n",
    "\n",
    "    # if we have sentinel-2, filter to sentinel-2 images only\n",
    "    item_details[\"sentinel\"] = item_details.platform.str.lower().str.contains(\n",
    "        \"sentinel\"\n",
    "    )\n",
    "    if item_details[\"sentinel\"].any():\n",
    "        item_details = item_details[item_details[\"sentinel\"] == True]\n",
    "\n",
    "    # return the closest imagery by time\n",
    "    best_item = item_details.sort_values(by=\"time_diff\", ascending=True).iloc[0]\n",
    "\n",
    "    return (best_item[\"item_obj\"], best_item[\"platform\"], best_item[\"datetime\"])\n",
    "\n",
    "\n",
    "def image_to_features(image_array):\n",
    "    \"\"\"\n",
    "    Convert an image array of the form (color band, height, width) to a\n",
    "    1-dimensional list of features. Returns a list where the first three\n",
    "    values are the averages of each color band, and the second three\n",
    "    values are the medians of each color band.\n",
    "    \"\"\"\n",
    "    averages = image_array.mean(axis=(1, 2)).tolist()\n",
    "    medians = np.median(image_array, axis=(1, 2)).tolist()\n",
    "\n",
    "    return averages + medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef3fe24a-c854-49fa-8367-cdaea9fcc84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK_DATA_DIR = DATA_DIR.parents[0] / \"benchmark\"\n",
    "\n",
    "# save image arrays in case we want to generate more features\n",
    "IMAGE_ARRAY_DIR = BENCHMARK_DATA_DIR / \"images\"\n",
    "IMAGE_ARRAY_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3309ff-4539-4613-8c55-320debe8a192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    17060\n",
       "test      6510\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a random subset of the training data for the benchmark\n",
    "train_subset = metadata[metadata[\"split\"] == \"train\"].sample(n=17060, random_state=2)\n",
    "\n",
    "# combine train subset with all test data\n",
    "metadata_subset = pd.concat([train_subset, metadata[metadata[\"split\"] == \"test\"]])\n",
    "metadata_subset.split.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5798075f-07db-45c1-b369-cb75a1c230b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(row):\n",
    "    pass\n",
    "    # check if we've already saved the selected image array\n",
    "    image_array_pth = IMAGE_ARRAY_DIR / f\"{row.uid}.npy\"\n",
    "\n",
    "    if image_array_pth.exists():\n",
    "        with open(image_array_pth, \"rb\") as f:\n",
    "            image_array = np.load(f)\n",
    "\n",
    "    # search and load the image array if not\n",
    "    else:\n",
    "        try:\n",
    "            ## QUERY STAC API\n",
    "            # get query ranges for location and date\n",
    "            search_bbox = get_bounding_box(\n",
    "                row.latitude, row.longitude, meter_buffer=50000\n",
    "            )\n",
    "            date_range = get_date_range(row.date, time_buffer_days=15)\n",
    "\n",
    "            # search the planetary computer\n",
    "            search = catalog.search(\n",
    "                collections=[\"sentinel-2-l2a\", \"landsat-c2-l2\"],\n",
    "                bbox=search_bbox,\n",
    "                datetime=date_range,\n",
    "            )\n",
    "            items = [item for item in search.get_all_items()]\n",
    "\n",
    "            ## GET BEST IMAGE\n",
    "            if len(items) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                best_item, item_platform, item_date = select_best_item(\n",
    "                    items, row.date, row.latitude, row.longitude\n",
    "                )\n",
    "                # add to dictionary tracking best items\n",
    "                selected_items[row.uid] = {\n",
    "                    \"item_object\": best_item,\n",
    "                    \"item_platform\": item_platform,\n",
    "                    \"item_date\": item_date,\n",
    "                }\n",
    "\n",
    "            ## CONVERT TO FEATURES\n",
    "            # get small bbox just for features\n",
    "            feature_bbox = get_bounding_box(\n",
    "                row.latitude, row.longitude, meter_buffer=2000\n",
    "            )\n",
    "\n",
    "            # crop the image\n",
    "            if \"sentinel\" in item_platform.lower():\n",
    "                image_array = crop_sentinel_image(best_item, feature_bbox)\n",
    "            else:\n",
    "                image_array = crop_landsat_image(best_item, feature_bbox)\n",
    "\n",
    "            # save image array so we don't have to rerun\n",
    "            image = np.transpose(image_array, axes=[1, 2, 0]).astype(np.uint8)\n",
    "            imageio.imwrite(IMAGE_ARRAY_DIR / f\"{row.uid}.png\", image)\n",
    "        # keep track of any that ran into errors without interrupting the process\n",
    "        except:\n",
    "            errored_ids.append(row.uid)\n",
    "    return \"ok\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029cb7e-55d7-4e81-be17-e6a38bffc8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 500/23570 [09:16<7:30:18,  1.17s/it]"
     ]
    }
   ],
   "source": [
    "import rioxarray\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "from PIL import Image as PILImage\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "# this cell takes a LONG time because it iterates over all data!\n",
    "\n",
    "# save outputs in dictionaries\n",
    "selected_items = {}\n",
    "features_dict = {}\n",
    "errored_ids = []\n",
    "\n",
    "\n",
    "# Perform the parallel computation using joblib\n",
    "results = Parallel(n_jobs=-1)(delayed(extract_images)(row) for row in tqdm(metadata_subset.itertuples(), total=len(metadata_subset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5926838f-ab2f-41d9-86a2-39556194234f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de96fcc-a13c-4e56-b43c-4232f35edf81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56855de2-3ad7-4583-b39d-fc81497b1421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
